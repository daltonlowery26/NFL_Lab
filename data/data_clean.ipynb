{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52909979",
   "metadata": {},
   "source": [
    "#### merging and combining all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6875e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Emory/NFL Lab/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec244f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weeks = []\n",
    "\n",
    "for root, dirs, files in os.walk('train/'):\n",
    "    week_files = {}\n",
    "    \n",
    "    # Group files by week number\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            week_num = file.split('_')[-1].replace('.csv', '')\n",
    "            \n",
    "            if week_num not in week_files:\n",
    "                week_files[week_num] = {}\n",
    "            \n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Categorize as input or output file\n",
    "            if 'output' in file:\n",
    "                week_files[week_num]['output'] = file_path\n",
    "            else:\n",
    "                week_files[week_num]['input'] = file_path\n",
    "    \n",
    "    # Process each week\n",
    "    for week_num, paths in week_files.items():\n",
    "        if 'input' in paths and 'output' in paths:\n",
    "            # Read input and output files\n",
    "            df = pd.read_csv(paths['input'])\n",
    "            df_throw = pd.read_csv(paths['output'])\n",
    "            \n",
    "            # Process and merge\n",
    "            df['play_id_n'] = df.groupby(['ball_land_x', 'ball_land_y', 'play_id']).ngroup()\n",
    "            \n",
    "            max_frames = df.groupby(['play_id', 'nfl_id'])['frame_id'].max().reset_index()\n",
    "            max_frames.columns = ['play_id', 'nfl_id', 'max_frame_id']\n",
    "            \n",
    "            df_2_extended = df_throw.merge(max_frames, on=['play_id', 'nfl_id'], how='inner')\n",
    "            df_2_extended['frame_id'] = df_2_extended['frame_id'] + df_2_extended['max_frame_id']\n",
    "            \n",
    "            common_cols = ['nfl_id', 'play_id', 'frame_id', 'x', 'y']\n",
    "            df_2_subset = df_2_extended[common_cols]\n",
    "            \n",
    "            df_combined = pd.concat([df, df_2_subset], ignore_index=True)\n",
    "            df_combined = df_combined.sort_values(['play_id', 'nfl_id', 'frame_id']).reset_index(drop=True)\n",
    "            \n",
    "            all_weeks.append(df_combined)\n",
    "\n",
    "# Merge all weeks together\n",
    "final_df = pd.concat(all_weeks, ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nflLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
